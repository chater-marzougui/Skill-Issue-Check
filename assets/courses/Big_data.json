{
  "Chapter 2 part 1": [
    {
      "question": "Quelle est la motivation principale derrière l'émergence du Big Data?",
      "options": [
        "La nécessité de réduire les coûts de stockage des données.",
        "L'augmentation massive des traces numériques laissées par les utilisateurs.",
        "Le besoin d'améliorer la sécurité des informations en ligne.",
        "La volonté de créer des systèmes d'exploitation plus performants."
      ],
      "answer": 1,
      "explanation": "La présence accrue des individus dans le monde virtuel et les quantités phénoménales de traces laissées sont la raison pour laquelle le Big Data est pertinent pour les entreprises."
    },
    {
      "question": "Quel est le rôle principal du Big Data pour les entreprises?",
      "options": [
        "Automatiser toutes les décisions stratégiques.",
        "Fournir un outil d'aide à la décision basé sur l'analyse des données.",
        "Remplacer les systèmes de gestion de base de données traditionnels.",
        "Minimiser l'interaction directe avec les clients."
      ],
      "answer": 1,
      "explanation": "Le Big Data est un outil d'aide à la décision en entreprise, permettant de mieux connaître prospects et clients et de bâtir des modèles solides."
    },
    {
      "question": "Quel framework a standardisé les outils de stockage et de traitement de données massives initialement développés par Google ?",
      "options": [
        "Apache Spark",
        "Hadoop",
        "Google Cloud Platform",
        "Microsoft Azure"
      ],
      "answer": 1,
      "explanation": "La fondation Apache est attribuée à la standardisation des outils de Google pour le Big Data à travers le framework 'Hadoop'."
    },
    {
      "question": "Sur quels principes de Google le projet Hadoop est-il basé ?",
      "options": [
        "Google Docs et Google Sheets",
        "Android et Chrome OS",
        "MapReduce et Google File System (GFS)",
        "Gmail et Google Calendar"
      ],
      "answer": 2,
      "explanation": "Hadoop est basé sur le principe MapReduce et Google File System, deux produits de Google Corp."
    },
    {
      "question": "Quelle est la fonction principale de GFS (Google File System) ?",
      "options": [
        "Un système de gestion de base de données relationnelle.",
        "Un environnement de développement intégré pour Java.",
        "Un système de fichier distribué optimisé pour le stockage de données ultra volumineuses.",
        "Un outil de virtualisation de serveurs."
      ],
      "answer": 2,
      "explanation": "GFS est un système de fichier distribué spécifiquement optimisé pour le stockage de données ultra volumineuses."
    },
    {
      "question": "Comment un fichier est-il stocké dans GFS?",
      "options": [
        "En une seule entité sur un serveur centralisé.",
        "Découpé en morceaux répartis sur des serveurs appelés Chunks Servers.",
        "Compressé et stocké dans une base de données NoSQL.",
        "Répliqué intégralement sur tous les serveurs du cluster."
      ],
      "answer": 1,
      "explanation": "Chaque fichier dans GFS est découpé en morceaux (chunks) qui sont ensuite répartis sur des serveurs appelés Chunks Servers."
    },
    {
      "question": "Quel composant de GFS connaît la localisation de tous les morceaux de fichiers ?",
      "options": [
        "Le Client GFS",
        "Le Chunks Server",
        "Le Master Server",
        "Le système d'exploitation Linux"
      ],
      "answer": 2,
      "explanation": "le Master Server dans GFS a pour rôle de connaître à chaque instant la localisation des morceaux (chunks) de fichiers."
    },
    {
      "question": "Quel est le modèle de programmation qui utilise le traitement parallèle pour accélérer le traitement de données à grande échelle?",
      "options": [
        "Orienté Objet",
        "Fonctionnel",
        "Impératif",
        "MapReduce"
      ],
      "answer": 3,
      "explanation": "MapReduce est un modèle de programmation conçu pour le traitement parallèle de données à grande échelle."
    },
    {
      "question": "Quelle est la première tâche effectuée dans le modèle MapReduce ?",
      "options": [
        "La tâche de réduction",
        "L'agrégation des valeurs",
        "La tâche de cartographie",
        "Le stockage des données"
      ],
      "answer": 2,
      "explanation": "La première tâche décrite pour le modèle MapReduce est la 'tâche de cartographie', qui transforme les données en paires clé/valeur."
    },
    {
      "question": "À quoi correspond la 'tâche de réduction' dans MapReduce ?",
      "options": [
        "Au découpage initial des données en morceaux.",
        "À la transformation des données en paires clé/valeur.",
        "À l'agrégation des valeurs avec la même clé et au traitement des données pour un résultat final.",
        "À la répartition des tâches sur les différents serveurs."
      ],
      "answer": 2,
      "explanation": "La 'tâche de réduction' prend les sorties de la tâche de cartographie, agrège les valeurs par clé et traite les données pour obtenir le résultat final."
    },
    {
      "question": "En quelle année le projet Hadoop a-t-il commencé ?",
      "options": [
        "2006",
        "2004",
        "2008",
        "2013"
      ],
      "answer": 1,
      "explanation": "L'histoire de Hadoop a commencé en 2004 avec le développement du système Nutch par Doug Cutting et Mike Cafarella."
    },
    {
      "question": "Quel système de recherche distribué a servi de base au développement initial d'Hadoop ?",
      "options": [
        "Google Search",
        "Yahoo! Search",
        "Nutch",
        "Apache Lucene"
      ],
      "answer": 2,
      "explanation": "Hadoop a commencé par être développé à partir de Nutch, un système de recherche distribué."
    },
    {
      "question": "Sous l'égide de quelle fondation Apache Hadoop est-il devenu un projet open source ?",
      "options": [
        "Apache Software Foundation",
        "Linux Foundation",
        "Eclipse Foundation",
        "Mozilla Foundation"
      ],
      "answer": 0,
      "explanation": "Hadoop est devenu un projet open source sous l'égide de l'Apache Software Foundation."
    },
    {
      "question": "Quel composant majeur a été introduit avec Hadoop 2.0 pour une gestion des ressources plus flexible ?",
      "options": [
        "HDFS",
        "MapReduce",
        "YARN",
        "Hive"
      ],
      "answer": 2,
      "explanation": "Hadoop 2.0 a introduit YARN (Yet Another Resource Negotiator) pour améliorer la gestion des ressources."
    },
    {
      "question": "quelle est l'une des principales caractéristiques d'Hadoop du point de vue du développeur ?",
      "options": [
        "Complexité du modèle de programmation.",
        "Déploiement lourd et coûteux.",
        "Modèle simple pour développer des tâches Map-Reduce.",
        "Gestion manuelle de la tolérance aux pannes."
      ],
      "answer": 2,
      "explanation": "Hadoop offre un modèle simple pour les développeurs pour créer des tâches Map-Reduce."
    },
    {
      "question": "Quel critère des solutions Big Data Hadoop assure-t-il en exploitant le parallélisme sur des clusters ?",
      "options": [
        "La sécurité.",
        "La gouvernance des données.",
        "La performance.",
        "L'interopérabilité."
      ],
      "answer": 2,
      "explanation": "La 'Performance' est un critère assuré par Hadoop, notamment grâce à l'exploitation du parallélisme."
    },
    {
      "question": "Quelle est la taille par défaut d'un bloc de données dans HDFS Hadoop V2 ?",
      "options": [
        "64 Mo",
        "128 Mo ou 256 Mo",
        "512 Mo",
        "1 Go"
      ],
      "answer": 1,
      "explanation": "La taille par défaut d'un bloc dans HDFS V2 est de 128 Mo ou 256 Mo."
    },
    {
      "question": "Pourquoi HDFS utilise-t-il des blocs de grande taille ?",
      "options": [
        "Pour augmenter le coût du stockage.",
        "Pour réduire le temps d'accès à un fichier.",
        "Pour simplifier la réplication des données.",
        "Pour améliorer la sécurité des données."
      ],
      "answer": 1,
      "explanation": "L'intérêt principal des blocs de grande taille dans HDFS est de réduire le temps d'accès aux fichiers."
    },
    {
      "question": "Quel est le rôle du NameNode dans HDFS ?",
      "options": [
        "Stocker les données réelles des fichiers.",
        "Gérer les métadonnées du système de fichiers (structure, localisation des blocs).",
        "Exécuter les tâches MapReduce.",
        "Gérer la réplication des blocs."
      ],
      "answer": 1,
      "explanation": "Le NameNode est la machine maîtresse dans HDFS qui gère les métadonnées du système de fichiers, incluant la localisation des blocs."
    },
    {
      "question": "Comment HDFS assure-t-il la tolérance aux pannes ?",
      "options": [
        "En stockant toutes les données sur un seul serveur principal.",
        "En ne permettant pas la suppression de fichiers.",
        "En répliquant les blocs de données sur plusieurs nœuds.",
        "En utilisant un système de fichiers journalisé."
      ],
      "answer": 2,
      "explanation": "HDFS assure la tolérance aux pannes en répliquant les blocs de données sur différents nœuds du cluster."
    }
  ],
  "Chapter 2 part 2": [
    {
      "question": "Quel est le rôle du Secondary NameNode dans HDFS ?",
      "options": [
        "Gérer les données réelles des fichiers.",
        "Agir comme un backup du NameNode en cas de défaillance.",
        "Stocker les métadonnées et gérer la réplication.",
        "Aider à la gestion des DataNodes."
      ],
      "answer": 1,
      "explanation": "Le Secondary NameNode aide à réduire la charge du NameNode principal en prenant périodiquement des instantanés de l'état du système de fichiers."
    },
    {
      "question": "Dans l'architecture HDFS, quel composant est considéré comme le maître et gère les métadonnées du système de fichiers ?",
      "options": [
        "DataNode",
        "NameNode",
        "Secondary NameNode",
        "Client HDFS"
      ],
      "answer": 1,
      "explanation": "Le NameNode est le composant maître dans un cluster HDFS, responsable de la gestion du namespace du système de fichiers et des métadonnées, y compris l'emplacement des blocs de données."
    },
    {
      "question": "Quel est le rôle principal d'un DataNode dans HDFS ?",
      "options": [
        "Gérer le namespace du système de fichiers",
        "Stocker les métadonnées des fichiers",
        "Stocker les blocs de données réels et servir les requêtes de lecture/écriture",
        "Coordonner les opérations entre le NameNode et les autres DataNodes"
      ],
      "answer": 2,
      "explanation": "Les DataNodes sont les nœuds esclaves qui stockent les blocs de données des fichiers HDFS et gèrent les opérations de lecture et d'écriture à la demande du client ou du NameNode."
    },
    {
      "question": "Quelle est la taille de bloc par défaut typique dans HDFS ?",
      "options": [
        "64 Mo",
        "128 Mo",
        "256 Mo",
        "512 Mo"
      ],
      "answer": 1,
      "explanation": "HDFS divise les fichiers en gros blocs pour le stockage distribué. La taille de bloc par défaut couramment utilisée est de 128 Mo ou 256 Mo."
    },
    {
      "question": "Pourquoi la réplication des données est-elle essentielle dans HDFS ?",
      "options": [
        "Pour réduire l'utilisation de l'espace disque",
        "Pour améliorer les performances d'écriture",
        "Pour assurer la tolérance aux pannes et la disponibilité des données",
        "Pour simplifier l'architecture du système"
      ],
      "answer": 2,
      "explanation": "La réplication des données (par défaut, un facteur de réplication de 3) dans HDFS garantit que les données restent accessibles même si certains DataNodes échouent, offrant ainsi une tolérance aux pannes et une haute disponibilité."
    },
    {
      "question": "Lors d'une opération de lecture dans HDFS, avec quel composant le client interagit-il en premier pour obtenir les emplacements des blocs de données ?",
      "options": [
        "Un DataNode aléatoire",
        "Le Secondary NameNode",
        "Le NameNode",
        "Directement avec le système de fichiers local"
      ],
      "answer": 2,
      "explanation": "Lors d'une lecture, le client HDFS contacte le NameNode pour obtenir les métadonnées du fichier, y compris la liste ordonnée des blocs et les DataNodes sur lesquels ils sont stockés."
    },
    {
      "question": "Quel principe suit HDFS concernant l'accès aux fichiers ?",
      "options": [
        "Écriture multiple, Lecture multiple",
        "Écriture une fois, Lecture une fois",
        "Écriture multiple, Lecture une fois",
        "Écriture une fois, Lecture multiple"
      ],
      "answer": 3,
      "explanation": "HDFS est optimisé pour les charges de travail par lots et suit le modèle 'Écriture une fois, Lecture multiple', ce qui le rend efficace pour l'analyse de grands ensembles de données."
    },
    {
      "question": "Que se passe-t-il si un DataNode échoue dans un cluster HDFS ?",
      "options": [
        "Le NameNode s'arrête immédiatement",
        "Les données sur ce DataNode deviennent définitivement inaccessibles",
        "Le NameNode détecte l'échec et initialise la réplication des blocs affectés sur d'autres DataNodes",
        "Le client bascule automatiquement vers le Secondary NameNode"
      ],
      "answer": 2,
      "explanation": "En cas de défaillance d'un DataNode, le NameNode s'en aperçoit via l'absence de 'heartbeats' et déclenche la duplication des blocs sous-répliqués pour maintenir le facteur de réplication défini."
    },
    {
      "question": "Quel est l'objectif principal de l'architecture maître-esclave de HDFS ?",
      "options": [
        "Simplifier les opérations de maintenance",
        "Permettre le traitement parallèle des données",
        "Centraliser la gestion des métadonnées et distribuer le stockage des données",
        "Minimiser les coûts matériels"
      ],
      "answer": 2,
      "explanation": "L'architecture maître-esclave de HDFS, avec le NameNode gérant les métadonnées et les DataNodes stockant les données, permet une gestion centralisée tout en distribuant efficacement le stockage et le traitement des grands ensembles de données."
    },
    {
      "question": "Lors de l'écriture d'un fichier dans HDFS, dans quel ordre les données sont-elles généralement écrites vers les DataNodes dans le pipeline de réplication ?",
      "options": [
        "Parallèlement à tous les DataNodes de la réplication",
        "Séquentiellement du client vers le premier DataNode, puis transmises le long du pipeline",
        "Directement du NameNode vers tous les DataNodes",
        "Dans un ordre aléatoire déterminé par chaque DataNode"
      ],
      "answer": 1,
      "explanation": "Lors de l'écriture, le client envoie les données au premier DataNode d'un pipeline. Ce DataNode écrit les données localement et les transmet simultanément au DataNode suivant dans le pipeline, et ainsi de suite."
    }
  ],
  "Chapter 2 part 3": [
  {
   "question": "Quelle est la première étape du processus MapReduce selon la description analogique de la préparation de sandwichs ?",
   "options": [
    "Map",
    "Shuffle/Group",
    "Split",
    "Reduce"
   ],
   "answer": 2,
   "explanation": "La première étape décrite est le 'Split', qui consiste à distribuer les ingrédients bruts parmi les travailleurs."
  },
  {
   "question": "Dans l'analogie de la préparation de sandwichs pour MapReduce, que représente l'étape 'Map' ?",
   "options": [
    "La distribution des ingrédients",
    "Le traitement individuel de chaque ingrédient",
    "Le regroupement des ingrédients traités",
    "L'assemblage final du sandwich"
   ],
   "answer": 1,
   "explanation": "L'étape 'Map' correspond au traitement individuel de chaque ingrédient par chaque travailleur, comme trancher les légumes."
  },
  {
   "question": "Que sont les 'mapper intermediates' dans le contexte de l'analogie MapReduce ?",
   "options": [
    "Les ingrédients bruts",
    "Les ingrédients après l'étape 'Map' (traités)",
    "Les sandwichs finis",
    "Les outils de préparation"
   ],
   "answer": 1,
   "explanation": "Les 'mapper intermediates' sont les ingrédients qui ont été traités lors de l'étape 'Map'."
  },
  {
   "question": "Quel est le rôle de l'étape 'Shuffle/Group' dans le processus MapReduce décrit ?",
   "options": [
    "Distribuer les tâches aux travailleurs",
    "Traiter les données individuellement",
    "Regrouper les résultats intermédiaires par clé",
    "Combiner les résultats finaux"
   ],
   "answer": 2,
   "explanation": "L'étape 'Shuffle/Group' consiste à regrouper les résultats intermédiaires ('mapper intermediates') avant l'étape de réduction."
  },
  {
   "question": "Selon le document, quelle est la fonction principale du JobTracker dans Hadoop ?",
   "options": [
    "Exécuter les tâches Map et Reduce directement",
    "Gérer et planifier l'exécution des jobs sur les TaskTrackers",
    "Stocker les données brutes",
    "Surveiller l'utilisation du disque"
   ],
   "answer": 1,
   "explanation": "Le JobTracker est responsable de la gestion globale et de la planification des 'jobs' (ensembles de tâches MapReduce) sur les TaskTrackers disponibles."
  },
  {
   "question": "Comment un TaskTracker communique-t-il son état et sa disponibilité au JobTracker ?",
   "options": [
    "En envoyant un message unique au début et à la fin de chaque tâche",
    "En mettant à jour une base de données centrale",
    "En envoyant régulièrement des messages 'heartbeats'",
    "Le JobTracker interroge directement les TaskTrackers quand il a besoin d'informations"
   ],
   "answer": 2,
   "explanation": "Les TaskTrackers envoient régulièrement des messages 'heartbeats' au JobTracker pour indiquer qu'ils sont toujours fonctionnels et pour signaler le nombre de 'slots' disponibles."
  },
  {
   "question": "Que contient un message 'heartbeat' envoyé par un TaskTracker au JobTracker, en plus d'indiquer qu'il est fonctionnel ?",
   "options": [
    "Le résultat final de la tâche en cours",
    "Le code source de la tâche exécutée",
    "Le nombre de 'slots' d'exécution disponibles",
    "L'adresse IP du TaskTracker"
   ],
   "answer": 2,
   "explanation": "En plus de signaler son bon fonctionnement, le message 'heartbeat' indique au JobTracker le nombre de 'slots' d'exécution disponibles sur le TaskTracker."
  },
  {
   "question": "Quand un TaskTracker envoie-t-il un message au JobTracker pour l'informer du résultat d'une sous-tâche ?",
   "options": [
    "Au début de l'exécution de la sous-tâche",
    "Uniquement si la sous-tâche échoue",
    "Une fois que la sous-tâche est terminée",
    "Régulièrement pendant l'exécution de la sous-tâche"
   ],
   "answer": 2,
   "explanation": "Lorsqu'une sous-tâche est terminée, le TaskTracker envoie un message au JobTracker pour l'informer de son achèvement et de son succès ou échec, en incluant le résultat."
  },
  {
   "question": "Qu'est-ce qu'un 'slot' d'exécution sur un TaskTracker ?",
   "options": [
    "Un espace de stockage pour les données intermédiaires",
    "Une unité d'exécution pour une tâche (Map, Reduce, Shuffle)",
    "Une connexion réseau avec le JobTracker",
    "Un fichier de configuration pour le TaskTracker"
   ],
   "answer": 1,
   "explanation": "Un 'slot' d'exécution sur un TaskTracker est une unité de capacité qui correspond à une tâche exécutable (Map, Reduce, Shuffle)."
  },
  {
   "question": "Quel est l'objectif principal de la décomposition d'un problème en étapes comme Split, Map, Shuffle/Group et Reduce dans le contexte de MapReduce ?",
   "options": [
    "Réduire la quantité totale de données à traiter",
    "Permettre le traitement distribué et parallèle de grands ensembles de données",
    "Simplifier la logique de l'application",
    "Minimiser l'utilisation de la mémoire"
   ],
   "answer": 1,
   "explanation": "L'idée fondamentale de MapReduce est de diviser un problème trop grand pour un seul ordinateur en étapes qui peuvent être exécutées en parallèle sur un cluster, permettant ainsi le traitement distribué de vastes quantités de données."
  },
  {
   "question": "Lorsqu'un TaskTracker reçoit une nouvelle tâche du JobTracker, que démarre-t-il ?",
   "options": [
    "Une nouvelle instance du JobTracker",
    "Une nouvelle instance de Java avec le fichier .jar fourni",
    "Un nouveau processus TaskTracker",
    "Une connexion SSH sécurisée"
   ],
   "answer": 1,
   "explanation": "Le TaskTracker démarre une nouvelle instance de Java, utilisant le fichier .jar contenant le code de la tâche fourni par le JobTracker, pour exécuter l'opération demandée (Map, Reduce, ou Shuffle)."
  },
  {
   "question": "Quel type de message est envoyé par le TaskTracker au JobTracker pour signaler si une sous-tâche s'est bien déroulée ?",
   "options": [
    "Un message 'heartbeat' spécial",
    "Un message d'erreur si elle a échoué",
    "Un message de achèvement incluant le statut (succès/échec)",
    "Aucune communication spécifique n'est envoyée pour le statut final"
   ],
   "answer": 2,
   "explanation": "Une fois la sous-tâche terminée, le TaskTracker envoie un message spécifique au JobTracker pour l'informer de son succès ou de son échec."
  },
  {
   "question": "Dans le contexte de Hadoop, quel composant est responsable de l'ordonnancement des tâches et de la gestion des ressources du cluster ?",
   "options": [
    "TaskTracker",
    "NameNode",
    "JobTracker",
    "DataNode"
   ],
   "answer": 2,
   "explanation": "Le JobTracker est l'élément central pour la gestion des jobs MapReduce, incluant l'ordonnancement des tâches sur les TaskTrackers disponibles."
  },
  {
   "question": "Quel est le rôle principal d'un TaskTracker dans le framework MapReduce de Hadoop ?",
   "options": [
    "Stocker des blocs de données",
    "Exécuter les tâches Map et Reduce assignées par le JobTracker",
    "Gérer les métadonnées du système de fichiers",
    "Coordonner la communication entre les JobTrackers"
   ],
   "answer": 1,
   "explanation": "Un TaskTracker est un agent sur chaque nœud de travail qui exécute les tâches spécifiques (Map ou Reduce) qui lui sont confiées par le JobTracker."
  },
  {
   "question": "Si un TaskTracker ne renvoie pas de message 'heartbeat' au JobTracker pendant une certaine période, comment le JobTracker interprète-t-il généralement cette situation ?",
   "options": [
    "Le TaskTracker est surchargé et très occupé",
    "Le TaskTracker a terminé toutes ses tâches",
    "Le TaskTracker est probablement tombé en panne",
    "Le réseau rencontre des problèmes de latence temporaires"
   ],
   "answer": 2,
   "explanation": "Le JobTracker utilise les 'heartbeats' comme un mécanisme pour détecter les TaskTrackers défaillants. L'absence de 'heartbeat' signale généralement un problème avec le TaskTracker."
  },
  {
   "question": "Quelle étape de MapReduce est explicitement mentionnée comme redémarrant une nouvelle instance de Java avec le fichier .jar fourni par le JobTracker sur le TaskTracker ?",
   "options": [
    "Split",
    "Map",
    "Shuffle/Group",
    "Les étapes Map, Reduce et Shuffle/Group démarrent une nouvelle instance"
   ],
   "answer": 3,
   "explanation": "Le document indique que lorsqu'il reçoit une nouvelle tâche à effectuer (MAP, REDUCE, SHUFFLE), le TaskTracker démarre une nouvelle instance de Java avec le fichier .jar."
  },
  {
   "question": "Que se passe-t-il une fois qu'une sous-tâche est démarrée par le TaskTracker ?",
   "options": [
    "Le TaskTracker arrête d'envoyer des messages 'heartbeat'",
    "Le TaskTracker commence à envoyer régulièrement des messages 'heartbeat' au JobTracker",
    "Le JobTracker envoie immédiatement une autre tâche au même TaskTracker",
    "Le TaskTracker attend la confirmation du JobTracker avant de commencer le traitement"
   ],
   "answer": 1,
   "explanation": "Une fois la tâche démarrée, le TaskTracker envoie régulièrement au JobTracker ses messages heartbeats pour indiquer qu'il est toujours opérationnel."
  },
  {
   "question": "Quel information, en plus du statut de fonctionnement, est incluse dans les messages 'heartbeat' envoyés par le TaskTracker ?",
   "options": [
    "Le nombre de tâches terminées depuis le dernier heartbeat",
    "La quantité de données traitées par les tâches en cours",
    "Le nombre de 'slots' disponibles sur le TaskTracker",
    "L'identifiant unique de la tâche en cours d'exécution"
   ],
   "answer": 2,
   "explanation": "En dehors d'informer le JobTracker qu'il est toujours fonctionnel, ces messages indiquent également le nombre de slots disponibles sur le TaskTracker concerné."
  }
  ]
}