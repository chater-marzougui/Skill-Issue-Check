{
  "Chapter 2 part 1": [
    {
      "question": "Quelle est la motivation principale derrière l'émergence du Big Data?",
      "options": [
        "La nécessité de réduire les coûts de stockage des données.",
        "L'augmentation massive des traces numériques laissées par les utilisateurs.",
        "Le besoin d'améliorer la sécurité des informations en ligne.",
        "La volonté de créer des systèmes d'exploitation plus performants."
      ],
      "answer": 1,
      "explanation": "La présence accrue des individus dans le monde virtuel et les quantités phénoménales de traces laissées sont la raison pour laquelle le Big Data est pertinent pour les entreprises."
    },
    {
      "question": "Quel est le rôle principal du Big Data pour les entreprises?",
      "options": [
        "Automatiser toutes les décisions stratégiques.",
        "Fournir un outil d'aide à la décision basé sur l'analyse des données.",
        "Remplacer les systèmes de gestion de base de données traditionnels.",
        "Minimiser l'interaction directe avec les clients."
      ],
      "answer": 1,
      "explanation": "Le Big Data est un outil d'aide à la décision en entreprise, permettant de mieux connaître prospects et clients et de bâtir des modèles solides."
    },
    {
      "question": "Quel framework a standardisé les outils de stockage et de traitement de données massives initialement développés par Google ?",
      "options": [
        "Apache Spark",
        "Hadoop",
        "Google Cloud Platform",
        "Microsoft Azure"
      ],
      "answer": 1,
      "explanation": "La fondation Apache est attribuée à la standardisation des outils de Google pour le Big Data à travers le framework 'Hadoop'."
    },
    {
      "question": "Sur quels principes de Google le projet Hadoop est-il basé ?",
      "options": [
        "Google Docs et Google Sheets",
        "Android et Chrome OS",
        "MapReduce et Google File System (GFS)",
        "Gmail et Google Calendar"
      ],
      "answer": 2,
      "explanation": "Hadoop est basé sur le principe MapReduce et Google File System, deux produits de Google Corp."
    },
    {
      "question": "Quelle est la fonction principale de GFS (Google File System) ?",
      "options": [
        "Un système de gestion de base de données relationnelle.",
        "Un environnement de développement intégré pour Java.",
        "Un système de fichier distribué optimisé pour le stockage de données ultra volumineuses.",
        "Un outil de virtualisation de serveurs."
      ],
      "answer": 2,
      "explanation": "GFS est un système de fichier distribué spécifiquement optimisé pour le stockage de données ultra volumineuses."
    },
    {
      "question": "Comment un fichier est-il stocké dans GFS?",
      "options": [
        "En une seule entité sur un serveur centralisé.",
        "Découpé en morceaux répartis sur des serveurs appelés Chunks Servers.",
        "Compressé et stocké dans une base de données NoSQL.",
        "Répliqué intégralement sur tous les serveurs du cluster."
      ],
      "answer": 1,
      "explanation": "Chaque fichier dans GFS est découpé en morceaux (chunks) qui sont ensuite répartis sur des serveurs appelés Chunks Servers."
    },
    {
      "question": "Quel composant de GFS connaît la localisation de tous les morceaux de fichiers ?",
      "options": [
        "Le Client GFS",
        "Le Chunks Server",
        "Le Master Server",
        "Le système d'exploitation Linux"
      ],
      "answer": 2,
      "explanation": "le Master Server dans GFS a pour rôle de connaître à chaque instant la localisation des morceaux (chunks) de fichiers."
    },
    {
      "question": "Quel est le modèle de programmation qui utilise le traitement parallèle pour accélérer le traitement de données à grande échelle?",
      "options": [
        "Orienté Objet",
        "Fonctionnel",
        "Impératif",
        "MapReduce"
      ],
      "answer": 3,
      "explanation": "MapReduce est un modèle de programmation conçu pour le traitement parallèle de données à grande échelle."
    },
    {
      "question": "Quelle est la première tâche effectuée dans le modèle MapReduce ?",
      "options": [
        "La tâche de réduction",
        "L'agrégation des valeurs",
        "La tâche de cartographie",
        "Le stockage des données"
      ],
      "answer": 2,
      "explanation": "La première tâche décrite pour le modèle MapReduce est la 'tâche de cartographie', qui transforme les données en paires clé/valeur."
    },
    {
      "question": "À quoi correspond la 'tâche de réduction' dans MapReduce ?",
      "options": [
        "Au découpage initial des données en morceaux.",
        "À la transformation des données en paires clé/valeur.",
        "À l'agrégation des valeurs avec la même clé et au traitement des données pour un résultat final.",
        "À la répartition des tâches sur les différents serveurs."
      ],
      "answer": 2,
      "explanation": "La 'tâche de réduction' prend les sorties de la tâche de cartographie, agrège les valeurs par clé et traite les données pour obtenir le résultat final."
    },
    {
      "question": "En quelle année le projet Hadoop a-t-il commencé ?",
      "options": [
        "2006",
        "2004",
        "2008",
        "2013"
      ],
      "answer": 1,
      "explanation": "L'histoire de Hadoop a commencé en 2004 avec le développement du système Nutch par Doug Cutting et Mike Cafarella."
    },
    {
      "question": "Quel système de recherche distribué a servi de base au développement initial d'Hadoop ?",
      "options": [
        "Google Search",
        "Yahoo! Search",
        "Nutch",
        "Apache Lucene"
      ],
      "answer": 2,
      "explanation": "Hadoop a commencé par être développé à partir de Nutch, un système de recherche distribué."
    },
    {
      "question": "Sous l'égide de quelle fondation Apache Hadoop est-il devenu un projet open source ?",
      "options": [
        "Apache Software Foundation",
        "Linux Foundation",
        "Eclipse Foundation",
        "Mozilla Foundation"
      ],
      "answer": 0,
      "explanation": "Hadoop est devenu un projet open source sous l'égide de l'Apache Software Foundation."
    },
    {
      "question": "Quel composant majeur a été introduit avec Hadoop 2.0 pour une gestion des ressources plus flexible ?",
      "options": [
        "HDFS",
        "MapReduce",
        "YARN",
        "Hive"
      ],
      "answer": 2,
      "explanation": "Hadoop 2.0 a introduit YARN (Yet Another Resource Negotiator) pour améliorer la gestion des ressources."
    },
    {
      "question": "quelle est l'une des principales caractéristiques d'Hadoop du point de vue du développeur ?",
      "options": [
        "Complexité du modèle de programmation.",
        "Déploiement lourd et coûteux.",
        "Modèle simple pour développer des tâches Map-Reduce.",
        "Gestion manuelle de la tolérance aux pannes."
      ],
      "answer": 2,
      "explanation": "Hadoop offre un modèle simple pour les développeurs pour créer des tâches Map-Reduce."
    },
    {
      "question": "Quel critère des solutions Big Data Hadoop assure-t-il en exploitant le parallélisme sur des clusters ?",
      "options": [
        "La sécurité.",
        "La gouvernance des données.",
        "La performance.",
        "L'interopérabilité."
      ],
      "answer": 2,
      "explanation": "La 'Performance' est un critère assuré par Hadoop, notamment grâce à l'exploitation du parallélisme."
    },
    {
      "question": "Quelle est la taille par défaut d'un bloc de données dans HDFS Hadoop V2 ?",
      "options": [
        "64 Mo",
        "128 Mo ou 256 Mo",
        "512 Mo",
        "1 Go"
      ],
      "answer": 1,
      "explanation": "La taille par défaut d'un bloc dans HDFS V2 est de 128 Mo ou 256 Mo."
    },
    {
      "question": "Pourquoi HDFS utilise-t-il des blocs de grande taille ?",
      "options": [
        "Pour augmenter le coût du stockage.",
        "Pour réduire le temps d'accès à un fichier.",
        "Pour simplifier la réplication des données.",
        "Pour améliorer la sécurité des données."
      ],
      "answer": 1,
      "explanation": "L'intérêt principal des blocs de grande taille dans HDFS est de réduire le temps d'accès aux fichiers."
    },
    {
      "question": "Quel est le rôle du NameNode dans HDFS ?",
      "options": [
        "Stocker les données réelles des fichiers.",
        "Gérer les métadonnées du système de fichiers (structure, localisation des blocs).",
        "Exécuter les tâches MapReduce.",
        "Gérer la réplication des blocs."
      ],
      "answer": 1,
      "explanation": "Le NameNode est la machine maîtresse dans HDFS qui gère les métadonnées du système de fichiers, incluant la localisation des blocs."
    },
    {
      "question": "Comment HDFS assure-t-il la tolérance aux pannes ?",
      "options": [
        "En stockant toutes les données sur un seul serveur principal.",
        "En ne permettant pas la suppression de fichiers.",
        "En répliquant les blocs de données sur plusieurs nœuds.",
        "En utilisant un système de fichiers journalisé."
      ],
      "answer": 2,
      "explanation": "HDFS assure la tolérance aux pannes en répliquant les blocs de données sur différents nœuds du cluster."
    }
  ],
  "Chapter 2 part 2": [
    {
      "question": "Quel est le rôle du Secondary NameNode dans HDFS ?",
      "options": [
        "Gérer les données réelles des fichiers.",
        "Agir comme un backup du NameNode en cas de défaillance.",
        "Stocker les métadonnées et gérer la réplication.",
        "Aider à la gestion des DataNodes."
      ],
      "answer": 1,
      "explanation": "Le Secondary NameNode aide à réduire la charge du NameNode principal en prenant périodiquement des instantanés de l'état du système de fichiers."
    },
    {
      "question": "Dans l'architecture HDFS, quel composant est considéré comme le maître et gère les métadonnées du système de fichiers ?",
      "options": [
        "DataNode",
        "NameNode",
        "Secondary NameNode",
        "Client HDFS"
      ],
      "answer": 1,
      "explanation": "Le NameNode est le composant maître dans un cluster HDFS, responsable de la gestion du namespace du système de fichiers et des métadonnées, y compris l'emplacement des blocs de données."
    },
    {
      "question": "Quel est le rôle principal d'un DataNode dans HDFS ?",
      "options": [
        "Gérer le namespace du système de fichiers",
        "Stocker les métadonnées des fichiers",
        "Stocker les blocs de données réels et servir les requêtes de lecture/écriture",
        "Coordonner les opérations entre le NameNode et les autres DataNodes"
      ],
      "answer": 2,
      "explanation": "Les DataNodes sont les nœuds esclaves qui stockent les blocs de données des fichiers HDFS et gèrent les opérations de lecture et d'écriture à la demande du client ou du NameNode."
    },
    {
      "question": "Quelle est la taille de bloc par défaut typique dans HDFS ?",
      "options": [
        "64 Mo",
        "128 Mo",
        "256 Mo",
        "512 Mo"
      ],
      "answer": 1,
      "explanation": "HDFS divise les fichiers en gros blocs pour le stockage distribué. La taille de bloc par défaut couramment utilisée est de 128 Mo ou 256 Mo."
    },
    {
      "question": "Pourquoi la réplication des données est-elle essentielle dans HDFS ?",
      "options": [
        "Pour réduire l'utilisation de l'espace disque",
        "Pour améliorer les performances d'écriture",
        "Pour assurer la tolérance aux pannes et la disponibilité des données",
        "Pour simplifier l'architecture du système"
      ],
      "answer": 2,
      "explanation": "La réplication des données (par défaut, un facteur de réplication de 3) dans HDFS garantit que les données restent accessibles même si certains DataNodes échouent, offrant ainsi une tolérance aux pannes et une haute disponibilité."
    },
    {
      "question": "Lors d'une opération de lecture dans HDFS, avec quel composant le client interagit-il en premier pour obtenir les emplacements des blocs de données ?",
      "options": [
        "Un DataNode aléatoire",
        "Le Secondary NameNode",
        "Le NameNode",
        "Directement avec le système de fichiers local"
      ],
      "answer": 2,
      "explanation": "Lors d'une lecture, le client HDFS contacte le NameNode pour obtenir les métadonnées du fichier, y compris la liste ordonnée des blocs et les DataNodes sur lesquels ils sont stockés."
    },
    {
      "question": "Quel principe suit HDFS concernant l'accès aux fichiers ?",
      "options": [
        "Écriture multiple, Lecture multiple",
        "Écriture une fois, Lecture une fois",
        "Écriture multiple, Lecture une fois",
        "Écriture une fois, Lecture multiple"
      ],
      "answer": 3,
      "explanation": "HDFS est optimisé pour les charges de travail par lots et suit le modèle 'Écriture une fois, Lecture multiple', ce qui le rend efficace pour l'analyse de grands ensembles de données."
    },
    {
      "question": "Que se passe-t-il si un DataNode échoue dans un cluster HDFS ?",
      "options": [
        "Le NameNode s'arrête immédiatement",
        "Les données sur ce DataNode deviennent définitivement inaccessibles",
        "Le NameNode détecte l'échec et initialise la réplication des blocs affectés sur d'autres DataNodes",
        "Le client bascule automatiquement vers le Secondary NameNode"
      ],
      "answer": 2,
      "explanation": "En cas de défaillance d'un DataNode, le NameNode s'en aperçoit via l'absence de 'heartbeats' et déclenche la duplication des blocs sous-répliqués pour maintenir le facteur de réplication défini."
    },
    {
      "question": "Quel est l'objectif principal de l'architecture maître-esclave de HDFS ?",
      "options": [
        "Simplifier les opérations de maintenance",
        "Permettre le traitement parallèle des données",
        "Centraliser la gestion des métadonnées et distribuer le stockage des données",
        "Minimiser les coûts matériels"
      ],
      "answer": 2,
      "explanation": "L'architecture maître-esclave de HDFS, avec le NameNode gérant les métadonnées et les DataNodes stockant les données, permet une gestion centralisée tout en distribuant efficacement le stockage et le traitement des grands ensembles de données."
    },
    {
      "question": "Lors de l'écriture d'un fichier dans HDFS, dans quel ordre les données sont-elles généralement écrites vers les DataNodes dans le pipeline de réplication ?",
      "options": [
        "Parallèlement à tous les DataNodes de la réplication",
        "Séquentiellement du client vers le premier DataNode, puis transmises le long du pipeline",
        "Directement du NameNode vers tous les DataNodes",
        "Dans un ordre aléatoire déterminé par chaque DataNode"
      ],
      "answer": 1,
      "explanation": "Lors de l'écriture, le client envoie les données au premier DataNode d'un pipeline. Ce DataNode écrit les données localement et les transmet simultanément au DataNode suivant dans le pipeline, et ainsi de suite."
    }
  ]
}